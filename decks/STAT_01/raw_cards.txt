Supervised Learning  	[latex]\begin{itemize}\item training set = input/output pairs\end{itemize}\begin{enumerate}\item classification: input = feature vector, output = discrete class label\item regression: input vector, output = continuous variable\end{enumerate}[/latex]
Unsupervised Learning  	[latex]\begin{itemize}\item training set = set of data points\end{itemize}\begin{enumerate}\item clustering = find groups of similar data (class labels assigned through similarity)\item density estimation = measure frequency of certain data points\end{enumerate}[/latex]
Joint Probability and Conditional Probability  	[latex]\begin{enumerate}\item joint probability $p(X,Y) = p(Y,X)$ is symmetric\item Conditional probability $p(X|Y) \neq p(Y|X)$ in general not symmetric\end{enumerate}[/latex]
Probability Theory: Sum rule/Marginalization 	[latex]\begin{equation*}p(X = \sum \limits{Y} p(X,Y)\end{equation*}allows computing probability of single event by summing joint probability overall possible events $Y$. $p(X)$ called marginal probability[/latex]
Probability Theory: Product Rule  	[latex]\begin{equation*}p(X,Y) = p(X|Y)p(Y)\end{equation*}[/latex]
Probability Theory: Independence of events  	[latex]\begin{enumerate}\item $X, Y$ independent iff $(p(Y|X) = p(Y)$ and $(p(X|Y) = p(X)$\item only in this case, joint distribution factorizes into product of marginals\begin{equation*}p(X,Y) = p(X)p(Y)\end{equation*}\end{enumerate}[/latex]
Bayes rule - Derivation 	[latex]From product rule and symmetry of joint probabilities:\begin{align*}&p(Y|X)p(X) = P(Y,X) = P(X,Y) = P(X|Y)p(Y)\\&\Rightarrow p(Y|X) = \frac{P(X|Y)p(Y)}{p(X)}\end{align*}[/latex]
Bayes rule  	TODO: INSERT IMAGE FROM SLIDE 14
Maximum likelihood(ML) vs Maximum a-posteriori(MAP)  	[latex]\begin{enumerate}\item likelihood evaluates candiate output on measurement $\Rightarrow$ seekingoutput that maximizes likelihood is known as maximum likelihood approach (ML)\item posterior probability is probability of $Y$ after taking measurement intoaccount $\Rightarrow$ seeking maximization of posterior probability is maximum a-posteriori approach (MAP)\end{enumerate}[/latex]
Probability Theory: Probability densities  	[latex]\begin{itemize}\item used for probabilities of \emph{continuous} variables\end{itemize}If probability of $x \in \mathbb{R}$ falling into interval $[x, x+dx]$ is givenby $p(x)dx$ for $dx \to 0$ then $p(x)$ is called probability density over$x$.\\ \\Properties of densities:\begin{enumerate}\item $p(x) \geq 0$\item $\int \limits_{\mathbb{R}} p(x) dx = 1$\end{enumerate}\begin{enumerate}\item probability that $x$ lies in interval $[a,b]$ can be derived fromprobability density by integration:\begin{equation*}p(x \in [a,b]) = \int \limits_{a}^{b} p(x) dx\end{equation*}$\Rightarrow$ cdf defined as:\begin{equation*}P(z) = \int \limits_{-\infty}^{z}p(x)dx\end{equation*}\end{enumerate}[/latex]
Probability Theory: Expectation  	[latex]\begin{enumerate}\item average of function $f(x)$ under Probability distribution $p(x)$:\begin{equation*}\mathbb{E}[f] = \int \limits_{\mathbb{R}} p(x) f(x) dx\end{equation*}\item for discrete events, integral turns into sum\begin{equation*}\mathbb{E}[f] = \sum \limits_{X} p(X) f(X)\end{equation*}\item can be estimated from $N$ samples:\begin{equation*}\mathbb{E}[f] \approx \frac{1}{N} \sum \limits_{i=1}^{N}f(x_i)\end{equation*}becomes exact for $N \to \infty$.\item Expectation over multiple variables:\begin{equation*}\mathbb{E}[f(x,y)]\mathbb \int \limits_{\mathbb{R}} p(x) f(x,y) dx\end{equation*}\item Conditional Expectation: \begin{equation*}\mathbb{E}[f|y)]\mathbb \int \limits_{\mathbb{R}} p(x|y) f(x) dx\end{enumerate}[/latex]
Probability Theory: Covariance  	[latex]\begin{enumerate}\item Variance of $f(x)$:\begin{equation*}var[f] = \mathbb{E}[(f(x) - \mathbb{E}[f(x)])^2] = \mathbb{E}[(f(x)^2] - \mathbb{E}[(f(x)]^2\end{equation*}\item Covariance of two scalar random variables:\begin{equation*}cov[x,y] = \mathbb{E}_{x,y}[(x-\mathbb{E}[x])(y-\mathbb{E}[y]) =\mathbb{E}_{x,y}[xy] - \mathbb{E}[x]\mathbb{E}[y]\end{equation*}measures extend to which $x, y$ vary together $\Rightarrow$ vanishes ifindependent.\item Covariance of two vectors $x,y \in \mathbb{R}^m$ yields $m\times m$covariance matrix:\begin{equation*}cov[x,y] = \mathbb{E}_{x,y}[(x-\mathbb{E}[x])(y^\top - \mathbb{E}[y^\top])] =\mathbb{E}_{x,y}[xy^\top] - \mathbb{E}[x] \mathbb{E}[y^\top]\end{equation*}- always symmetric\\- positive semi-definite iff $y=x$ (covariance of vector with itself)\end{enumerate}[/latex]
Probability Theory: Inference and decision theory  	[latex]\begin{enumerate}\item Inference is process to derive probability distributions from data.\item in applications, more often interested in decision (rather thandistribution) $\Rightarrow$ decision theory $=$ derive optimal decisions fromdistributions\item optimality of decision strategy depends on way how wrong decisions arepenalized $=$ loss function\end{enumerate}[/latex]
Probability Theory: Loss function 	[latex]\begin{itemize}\item specifies how much we must pay for wrong decisions\end{itemize}[/latex]
probability theory: reject option  	[latex]\begin{itemize}\item in some applications: good to avoid decisions in case of large uncertainty\item reject input in case maximum posterior is below threshold $\theta$\end{itemize}[/latex]TODO: INSERT IMAAGE SLIDE 25
Probability Theory - Combining inference and decision (based on bayes formula): Generative models  	[latex]\begin{enumerate}\item learn likelihood + prior probabilities from training data\item from those compute posterior to make decision\item one can generate new inputs from distributions $\Rightarrow$ generativemodels\item most complex, since inputs tend to be high-dimensional\end{enumerate}[/latex]
 Probability Theory - Combining inference and decision (based on bayes formula):Discriminative Models  	[latex]\begin{enumerate}\item directly learn posterior distribution from data\item no generation of inputs possible, less complex since outputdimensionality usually smaller than input dimensionality\end{enumerate}[/latex]
  Probability Theory - Combining inference and decision (based on bayes formula):Mappings 	[latex]\begin{enumerate}\item directly learn mapping from input to output\item probabilities do not play a role anymore\end{enumerate}[/latex]
 Probability Theory - Combining inference and decision (based on bayes formula):Comparison/Discussion 	[latex]\begin{enumerate}\item generative models $=$ most sense if prior should be controllable\item mappings can be learned even from very few data, but:\begin{itemize}\item do not know how much we can trust decision$\Rightarrow$ no reject option\item combination of models in probabilistic manner no longer possible\end{itemize}\end{enumerate}[/latex]
