SATzilla - Training  	[latex]\begin{enumerate}\item identify instances and features\item select (complementary) porfolio of candidates \item on training set compute features and run all algos to get runtimes\item find one or more algos for pre-solving schedule (brute-force search)\item construct EPM for each algorithm $\Rightarrow$ best subset of solvers infinal portfolio\end{enumerate}[/latex]
SATzilla - Selection  	[latex]\begin{enumerate}\item run pre-solving schedule\item compute feature values, if fails use backup solver\item else use features to predict runtimes (EPMS)\item run best predicted algorithm (if crashs, switch to next best)\end{enumerate}[/latex]
Runtime predictions: Ridge regression  	[latex]Given:\begin{itemize}\item feature vectors $f(\pi)$ characterize instances $\pi \in I$. \item log-runtime measured as $y_{ \mathcal{A}, \pi} = \log t( \mathcal{A},\pi)$\end{itemize}Problem:\begin{itemize}\item ridge regression suffers from highly correlated and uninformativefeatures\\$\Rightarrow$ use forward feature selection\item add quadratic basis features $f_j(\pi) f_k(\pi), j \in \{1, \dots, m \}k= \{j \dots m\}$ $\Rightarrow$ use another pass of forward feature selection:\\$\rightarrow \phi_{\pi} = \phi(f(\pi))$\item collect forward-selected features of all instances in matrix $\Phi$\item $w = (\delta I + \Phi^\top \Phi)^{-1} \Phi^\top y$ ($\delta$ smallconstant to penalize large coefficients $w$\item $f_w(f(\pi)) = w^\top \phi(f(\pi))$\end{itemize}[/latex]
Accounting for Censored data  	[latex]Problem:\\measured runtimes include timeouts (left-censored data, only lower-bound onruntime known)\\ \\Solution:\\train additional EPM to detect left-censored predictions of old EPM[/latex]
Hierarchical EPMs  	[latex]Idea: \begin{enumerate}\item use machine learning to predict probabilities of SAT/UNSAT\item learn different EPMS for SAT/UNSAT instances\end{enumerate}[/latex]
SATzilla'11: cost-sensitive classification  	[latex]Idea:\\ SATzilla trains EPM for ALL algorithms to predict runtime\\$\Rightarrow$ not interested in performance of each algorithm, but in RANKINGof the algorithms\\ $\Rightarrow$ pairwise classification to rank algorithms\\ \\Implementation:\\\begin{itemize}\item train cost-sensitive random forest classificator for each pair ofalgorithms $( \mathcal{A}_1, \mathcal{A}_2)$ (weigh instances by performancedifference between $ \mathcal{A}_1$ and $ \mathcal{A}_2$)\item each predicted class gives vote to either algorithm\item select algorithm with most votes\end{itemize}[/latex]
Pairwise Regression Models  	[latex]\begin{enumerate}\item predict performance difference between each pair of algorithms: $( \delta \mathcal{A}_1, \mathcal{A}_2)$ \item score each algorithm by sum of performance differences:\begin{equation*}score( \mathcal{A} ) = \sum \limits_{ \mathcal{A}' \in \mathcal{P}} \delta(\mathcal{A}, \mathcal{A}')\end{equation*}\item select algorithm with smallest score\end{enumerate}[/latex]
Cost-Sensitive Hierarchical Clustering: CSHC  	[latex]Approach - Training:\begin{enumerate}\item train decision tree s.t. each leaf maximally agrees on best-performingalgorithm $=$ homogeneous instance sets\item uses bagging to improve performance further\end{enumerate}Homogeneous Metric (single best $-$ oracle):\begin{equation*}h(I) = \min \limits_{ \mathcal{A} \in \mathcal{P}} \sum \limits_{\pi \in I}m(\pi, \mathcal{A}) - \sum \limits_{\pi \in I} \min \limits_{ \mathcal{A} \in\mathcal{P}} m(\pi, \mathcal{A}) - \end{equation*}Split criterion:\\Split $I$ into $I_1$ and $I_2$ s.t.:\\\begin{equation*}(I_1, I_2) \in arg \min \limits_{I_1 \cup I_2 = I} h(I_1) + h(I_2) \end{equation*}[/latex]
3S  	[latex]Idea: similar instances in feature space have same well-performing algorithms\\Training:\begin{enumerate}\item compute time-out-minimal pre-solving schedule using MIP\item train selector based on k-nn with clustering-based adaptive neighborhoodsize\end{enumerate}Selection:\begin{enumerate}\item For $10$ percent of runtime cutoff, run pre-solving schedule\item determine $k$ most similar instances $I_k$ in feature space\item select solver with best performance on $I_k$\end{enumerate}[/latex]
