Manual Expert Approach: Algorithm Configuration on Heterogeneous Instancesets  	[latex]Idea: expert knows homogeneous subsets\begin{itemize}\item determine well-performing configuration on each subset (yields portfolio)\item use algorithm selection to select well-performing configuration on eachinstance\end{itemize}[/latex]
Instance-Specific Algorithm Configuration (ISAC) (Algorithm Configuration on Heterogeneous Instancesets) 	[latex]Training:\begin{enumerate}\item Cluster instances into homogeneous subsets (g-means in feature space)\item apply algorithm configuration (GGA) on each instance set\end{enumerate}Test:\begin{enumerate}\item determine nearest cluster (k-NN with $k=1$) in feature space\item apply optimized configuration of this cluster\end{enumerate}Problems:\\clustering (unsupervised learning) $=$ sensitive to scale anddistance metric in feature space hard to pick\\cannot assess quality of clusters [/latex]
EISAC - Configuration on heterogeneous instancesets  	[latex]Motivation\begin{enumerate}\item Over time, types of problems portfolio should solve change\item all-encompassing training set doesn't exist\\$\Rightarrow$ selector must evolve over time\end{enumerate}Idea\begin{enumerate}\item update cluster if we see instance that aren't represented\item update solver selection for cluster that grew\item add and remove solvers and update clusters\end{enumerate}[/latex]
ISAC+ for algorithm configuration on heterogeneous instance sets  	[latex]Observations:\begin{enumerate}\item not important to apply configuration found on a cluster\item arbitrary algoselection possible\end{enumerate}Idea\begin{enumerate}\item cluster instances\item apply algoconfig on each cluster\item assess performance of all configs on each instance\item use cost-sensitive hierarchical clustering for algoselection\end{enumerate}[/latex]
Hydra - algoconfiguration on heterogeneous instance sets  	[latex]Idea:\begin{enumerate}\item iteratively add configurations to portfolio $ \mathcal{P}$, start with$ \mathcal{P} = \varnothing$\item in each iteration, determine configuration complementary to $ \mathcal{P}$\end{enumerate}Marginal contribution of configuration $\theta$ to portfolio $ \mathcal{P}$:\begin{equation*}m( \mathcal{P} ) - m ( \mathcal{P} \cup \{\theta \})\end{equation*}ADD IMAGE FROM SLIDE 12[/latex]
Cedalion - Algo Configuration on heterogeneous instancesets  	[latex]Idea: optimize schedule of configurations using algorithm configuration\\ \\Approach:\begin{enumerate}\item iteratively add configuration with time slot $t$ to a schedule $S\bigoplus \langle \theta, t \rangle$\item in each iteration only optimizeon instances unsolved so far\item time slot is further parameter in configuration space\item optimize marginal contribution per time spent\begin{equation*}\frac{m( \mathcal{S}  ) - m( \mathcal{S} \bigoplus \langle \theta, t\rangle)}{t}\end{equation*}\end{enumerate}[/latex]
Submodularity  	[latex]examples: Hydra, Cedalion performance metrics\begin{itemize}\item Family of functions\item adding element to set reduces function value\item diminishing returns: decrease of this reduction over time\end{itemize}Definition: Submodularity of $f$:\\For every $X,Y \subseteq Z$ with $X \subseteq Y$ and every $x \in Z-Y$ we havethat $f(X \cup \{x\}) -f(x) \geq f(Y \cup \{x\}) -f(Y)$\\ \\Advantage: can bound error of schedule[/latex]
Ablation: Parameter Importance Approach  	[latex]Idea:\begin{enumerate}\item starting from default configuration, change value of parameters, notewhich changes were important\\$\Rightarrow$ compare parameter flips between default and incumbent configuration\end{enumerate}Approach:\begin{enumerate}\item iterate over flipped parameters\item flip parameter with largest influence on performance in each iteration\end{enumerate}with racing:\begin{itemize}\item to determine best flip in each iteration, use racing with statisticaltest to speed up decision\end{itemize}[/latex]
Forward Selection: Parameter Importance  	[latex]Idea:\begin{enumerate}\item which parameters needed to train empirical performance model?\item use forward selection to identify important parameters (+ instances)\item minimize root mean squared error on validation set\item limit maximal number of selected parameters\end{enumerate}[/latex]
fANOVA: Parameter Importance  	[latex]Idea: Write performance predictions as sum of components\begin{align*}\hat{y}(\theta_1, \dots, \theta_n) &= \hat{f}_0 + \sum \limits_{i=1}^{n}\hat{f}_i(\theta_i) + \sum \limits_{i \neq j} \hat{f}_{ij}(\theta_i, \theta_j)+ \dots\\\hat{y}(\theta_1, \dots, \theta_n) &= \text{ average response } + \text{ maineffects } + \text{ 2-D interaction effects} + \text{ higher order effects }\end{align*}Variance decomposition:\begin{equation*}V = \frac{1}{||\Theta||} \int_{\theta_1}\dots \int_{\theta_n}[\hat{y}(\theta) -\hat{f}_0)^2]d\theta_1 \dots d\theta_n\end{equation*}Parameter importance:\\How much of variance can be explained by a Parameter or combinations containingit marginalized over all other parameters?[/latex]
Comparison Parameter Importance Approaches  	[latex]Ablation:\\$+$ only method to compare two configurations\\$-$ slow (lots of algorithm runs required)\\ \\Forward Selection:\\$+$ EPM can be trained by performance data collected during configuration\\$+/-$ considers complete configuration space\\$-$ slow if training EPM is slow (repeated!)\\\\fANOVA:\\$+$ EPM can be trained by performance data collected during configuration\\$+$ considers complete configuration space or only interesting areas\\$-$ importance of interactions bettween parameters can be expensive\\\\[/latex]
