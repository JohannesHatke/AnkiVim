Algorithm Configuration - Full Formal Definition  	[latex]Algorithm Configuration problem is $5$-tuple $( \mathcal{A}, \Theta,\mathcal{D}, \kappa, m)$ where:\begin{itemize}\item $ \mathcal{A}$ is parameterized algorithm\item $ \mathcal{D}$ is distribution over problem instances with domain\mathcal{I}\item $\kappa < \infty$ is cutoff after which algo $\mathcal{A}$ will beterminated\item $m : I \times \Theta \to \mathbb{R}$ is function that measures observedcost of running $ \mathcal{A}(\Theta)$ on an instance $\pi \in I$ with cutoff$\kappa$\end{itemize}cost of a candidate solution $\theta \in \Theta$ is:\begin{equation*}c(\theta) = \mathbb{E}_{\pi \sim \mathcal{D} }(m(\pi, \theta))\end{equation*}goal $=$ finding:\begin{equation*}\theta^* \in arg \min \limits_{\theta \in  \Theta} c(\theta)\end{equation*}[/latex]
Algorithm Configuration - Why do we need a cutoff time?  	[latex]-Some configurations can be very poor and never solve an instance\\- Algorithm Configuration with cutoff $\kappa = \infty$ is undecidable.\\ \\Proof by reduction of halting problem to algorith comfinguration:\\\begin{itemize}\item Define cost of my\_algo with one boolean parameter:\begin{align*}m(\pi, \theta = true) &= 1 \text{ if new algo A halts on } \pi \text { else } 0\\m(\pi, \theta = false) = 0.5\end{align*}\item Now solving algo config for my\_algo and $\pi$ solves halting problem for$A$:\begin{itemize}\item $\theta* = false$ implies that $A$ halts on $\pi$\item $\theta* = true$ implies that $A$ does not halt on $\pi$\end{itemize}\end{itemize}[/latex]
Algorithm Configuration - Parameter Types  	[latex]\begin{itemize}\item Continuous, integer, ordinal\item Categorical: finite domain, unordered $\{apple, tomato, pepper \}$\end{itemize}Structure of Parameter space:\begin{itemize}\item Conditional parameters: only active depending on other parameter values(e.g. heuristics)\end{itemize}Parameter tuning vs Algorithm Configuration:\\Algo Configuration $=$ space of possible configurations (combinations ofparameter value assignments)[/latex]
Challenges of Algorithm Configuration  	[latex]\begin{itemize}\item Structured high-dimensional parameter space\begin{itemize}\item categorical vs continuous parameters\item conditionals between parameters\end{itemize}\item stochastic optimization\begin{itemize}\item randomized algorithms: optimization across various seeds\item distribution of benchmark instances (varying hardness)\end{itemize}\item heterogeneous instance sets (no single configuration performs well on allinstances)\end{itemize}[/latex]
What would be the most naive approach for algorithm configuration?  	[latex]modify single parameter at a time greedily, keep new configuration if benchmarkset performance improves\\$\Rightarrow$ manually-executed first-improvement local search\\$\Rightarrow$ improvable using any advanced SLS method[/latex]
Concept of overtuning  	[latex]related to overfitting in machine learning\begin{itemize}\item Performance imporves on training set but not on test set (may get worsethere)\item more pronounced for more heterogeneous benchmark sets\item can even overtune/overfit on single instance, to seeds used for training\end{itemize}[/latex]
When is overtuning most pronounced?  	[latex]\begin{itemize}\item heterogeneous instance sets\item smaller training sets\end{itemize}[/latex]
FocusedILS (Algo Configuration): Intuition/General Idea  	[latex]Intuition: get best of both worlds\begin{itemize}\item more runs for good configurations (avoid overtuning)\item quickly reject poor configurations (make progress quickly)\end{itemize}[/latex]
FocusedILS: Domination Definition  	[latex]Let $N(\theta)$ be the number of runs executed for $\theta$ currently.\\Let $\hat{c}_N(\theta)$ be the cost estimate of $\theta$ based on $N$ runs.\\ \\$\theta_1$ dominates $\theta_2$ if\begin{enumerate}\item $N(\theta_1) \geq N(\theta_2)$\item $\hat{c}_{N(\theta_2)}(\theta_1) \leq \hat{c}_{N(\theta_2)}(\theta_2)$\end{enumerate}"We have at least as many runs for $\theta_1$ and its cost up to the smallernumber of runs (runs for $\theta_2$) is at least as low[/latex]
[latex]ParamILS in general (Focused ILS, Basic ILS, etc): \\When is a configuration assumed to be better than another one?(Give definition for $better_{F_{oc}}(\theta', \theta')!$)[/latex] 	[latex]$\theta$ is current incumbent.\\\\Perform runs of new configuration $\theta'$ until either\begin{itemize}\item $\theta$ domaintes $\theta'$ $\Rightarrow$ reject $\theta'$\item $\theta'$ domaintes $\theta$ $\Rightarrow$ change incumbent: $(\theta\leftarrow \theta')$\item over time: perform extra runs of $\theta$ to gain more confidence\end{itemize}[/latex]
Convergencce of Focused ILS (Theorem and Proof Sketch)  	[latex]Let $\Theta$ be finite. Then, probability that FocusedILS finds true optimalparameter configuration $\theta* \in \Theta$ approaches $1$ as number ofiterations goes to infinity.\\ \\Proof sketch:\\\begin{enumerate}\item In every iteration, every $\theta$ can be run with probability $> 0$(ParamILS is PAC (probabilistically approximate complete)\item for any fixed $N$ and $\theta$, we will eventually have $\geq N$evaluations of $\theta$\item As $N \to \infty$, comparisons based on sample means $\hat{c}_N$ arecorrect\begin{itemize}\item sample mean $\hat{c}_N$ approaches true expectation $c(\theta)$\item If $c(\theta_1) > c(\theta_2)$, then $\lim \limits_{N \to \infity}P(\hat{c_N}(\theta_1) > \hat{c_N}(\theta_2)) = 1$\end{itemize}\end{enumerate}[/latex]
Different Types of Overtuning  	[latex]\begin{enumerate}\item to instances in training set\item to seeds used in training set\item to (small) runtime cutoff\item to particular machine type\item to type of instances in training set (should be drawn according todistribution of interest, but distribution might change over time)\end{enumerate}[/latex]
Adaptive capping  	[latex]Assumptions\begin{itemize}\item optimization of runtime\item each configuration run has cutoff time \end{itemize}Idea: terminate evaluation of $\theta'$ early: once guaranteed to be worse than$\theta$\\ \\$\Rightarrow$ to compare against $\theta$ based on $N$ runs, we can terminateevaluation of $\theta'$ after time $\sum \limits_{i=1}^{N} m(\pi_i, \theta)$\\\\Does not change trajectory of ParamILS, only makes it faster[/latex]
ParamILS: Idea and Implementations  	[latex]Perform biased random walk over local optima\\Implementation:\begin{enumerate}\item perturbation: $3$ random moves in $1$-exchange neighbourhood\item subsidiary local search: greedy first improvement\item acceptance criterion: always improve better configuration\end{enumerate}Perform sequence of pairwise comparisions: is new configuration better thancurrent imcumbent? Can be estimated differently: BasicILS better vs FocusedILSbetter[/latex]
BasicILS(N)  	[latex]BasicILS = basic comparison: $better_N(\theta', \theta)$\\compare $\theta', \theta$ based on $N$ instances similar to cross-validation\\\\Problem: large $N = $ slow evaluations, small $N$ overtuning to smallinstanceset\\$\Rightarrow$Tradeoff, moderate $N$\\ \\Important: use same $N$ instances and same seeds for both configurations[/latex]
