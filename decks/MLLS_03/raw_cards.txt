Sources of Uncertainty -- Probability &nbsp;<div><br /></div> &nbsp;<div><br /></div>	 &nbsp;<div><br /></div>[latex]&nbsp;<div><br /></div>\begin{enumerate}&nbsp;<div><br /></div>\item noise in measurements&nbsp;<div><br /></div>\item finite sampling&nbsp;<div><br /></div>\item intrinsic stochastic phenomena&nbsp;<div><br /></div>\end{enumerate}&nbsp;<div><br /></div>[/latex] &nbsp;<div><br /></div>
Notation: Trials -- Probability &nbsp;<div><br /></div>&nbsp;<div><br /></div>	 &nbsp;<div><br /></div>[latex]&nbsp;<div><br /></div>\begin{enumerate}&nbsp;<div><br /></div>\item $n_{ij}$ is num of trials in which random variables $X = x_i$ and $Y = y_j$&nbsp;<div><br /></div>\item $c_i$ is num of trials in which $X = x_i$ irrespective of value that $Y$&nbsp;<div><br /></div>takes&nbsp;<div><br /></div>\item $r_j$ is num of trials in which $Y=y_j$ irrespective of value that $X$&nbsp;<div><br /></div>takes&nbsp;<div><br /></div>\end{enumerate}&nbsp;<div><br /></div>[/latex]&nbsp;<div><br /></div> &nbsp;<div><br /></div>
Joint probability -- Probability &nbsp;<div><br /></div>&nbsp;<div><br /></div> &nbsp;<div><br /></div>	 &nbsp;<div><br /></div>[latex]&nbsp;<div><br /></div>\begin{equation*}&nbsp;<div><br /></div>p(X=x_i, Y=y_j) = \frac{n_{ij}}{N}&nbsp;<div><br /></div>\end{equation*}&nbsp;<div><br /></div>[/latex] &nbsp;<div><br /></div>
Marginal probability -- Probability &nbsp;<div><br /></div> &nbsp;<div><br /></div>	 &nbsp;<div><br /></div>[latex]&nbsp;<div><br /></div>\begin{equation*}&nbsp;<div><br /></div>p(X=x_i) = \frac{c_i}{N}&nbsp;<div><br /></div>\end{equation*}&nbsp;<div><br /></div>where $c_i = \sum \limits_j n_{ij}&nbsp;<div><br /></div>[/latex] &nbsp;<div><br /></div>
Conditional probability -- probability &nbsp;<div><br /></div> &nbsp;<div><br /></div>	 &nbsp;<div><br /></div>[latex]&nbsp;<div><br /></div>\begin{equation*}&nbsp;<div><br /></div>p(Y=y_j \mid X = x_i) = \frac{n_{ij}}{c_i}&nbsp;<div><br /></div>\end{equation*}&nbsp;<div><br /></div>[/latex] &nbsp;<div><br /></div>
Sum/Product rule of probability -- Probability &nbsp;<div><br /></div> &nbsp;<div><br /></div>	 &nbsp;<div><br /></div>[latex]&nbsp;<div><br /></div>sum rule:&nbsp;<div><br /></div>\begin{equation*}&nbsp;<div><br /></div>p(X=x_i) = \frac{c_i}{N} = \frac{1}{N} \sum \limits_j n_{ij} = &nbsp;<div><br /></div>\sum \limits_j p(X=x_i, Y=y_j)&nbsp;<div><br /></div>\end{equation*}&nbsp;<div><br /></div>product rule:&nbsp;<div><br /></div>\begin{equation*}&nbsp;<div><br /></div>p(X=x_i, Y=y_j) = \frac{n_{ij}}{N} = \frac{n_{ij}}{c_i}\frac{c_i}{N} = &nbsp;<div><br /></div>p(Y=y_j \mid X=x_i) p(X=x_i)&nbsp;<div><br /></div>\end{equation*}&nbsp;<div><br /></div>[/latex] &nbsp;<div><br /></div>
Bayes Theorem -- Probability &nbsp;<div><br /></div>&nbsp;<div><br /></div> &nbsp;<div><br /></div>	 &nbsp;<div><br /></div>[latex]&nbsp;<div><br /></div>\begin{equation*}&nbsp;<div><br /></div>p(Y \mid X) = \frac{p(X|Y) p(Y)}{p(X)} = \frac{p(X|Y) p(Y)}{\sum \limits_Y&nbsp;<div><br /></div>p(X|Y) p(Y)}&nbsp;<div><br /></div>\end{equation*}&nbsp;<div><br /></div>can be read as:&nbsp;<div><br /></div>\begin{equation*}&nbsp;<div><br /></div>\text{posterior} = \frac{\text{likelihood} \times \text{prior}}{\text{evidence}}&nbsp;<div><br /></div>\end{equation*}&nbsp;<div><br /></div>[/latex] &nbsp;<div><br /></div>
Independence -- Probability &nbsp;<div><br /></div> &nbsp;<div><br /></div>	 &nbsp;<div><br /></div>[latex]&nbsp;<div><br /></div>Condition:&nbsp;<div><br /></div>\begin{equation*}&nbsp;<div><br /></div>p(X,Y) = p(X) p(Y)&nbsp;<div><br /></div>\end{equation*}&nbsp;<div><br /></div>This is equivalent to:&nbsp;<div><br /></div>\begin{equation*}&nbsp;<div><br /></div>p(Y \mid X) = p(Y)&nbsp;<div><br /></div>\end{equation*}&nbsp;<div><br /></div>distribution of $Y$ given specific value for $X$ is independent from actual&nbsp;<div><br /></div>value of $X$&nbsp;<div><br /></div>[/latex] &nbsp;<div><br /></div>
Probability densities -- Probability &nbsp;<div><br /></div> &nbsp;<div><br /></div>	 &nbsp;<div><br /></div>[latex]&nbsp;<div><br /></div>\begin{itemize}&nbsp;<div><br /></div>\item probabilities can also be defined for continuous variables&nbsp;<div><br /></div>\item if $p(x)\delta x$ for $\delta x \to 0$ gives probability of real-valued&nbsp;<div><br /></div>variable $x$ falling in interval $(x, x+\delta x)$ then $p(x)$ is&nbsp;<div><br /></div>\emph{probability density} over $x$&nbsp;<div><br /></div>\item in general, probability that $x$ will lie in interval $(a, b)$ given by:&nbsp;<div><br /></div>\begin{equation*}&nbsp;<div><br /></div>p(x \in (a,b)) = \int \limits_{a}{b} p(x) dx&nbsp;<div><br /></div>\end{equation*}&nbsp;<div><br /></div>\item sum, product rule become:&nbsp;<div><br /></div>\begin{align*}&nbsp;<div><br /></div>p(x) &= \int p(x,y)dy\\&nbsp;<div><br /></div>p(x, y) &= \int p(y \mid x) p(x)&nbsp;<div><br /></div>\end{align*}&nbsp;<div><br /></div>\end{itemize}&nbsp;<div><br /></div>[/latex] &nbsp;<div><br /></div>
Decision Theory: key notions -- Probability &nbsp;<div><br /></div> &nbsp;<div><br /></div>	 &nbsp;<div><br /></div>[latex]&nbsp;<div><br /></div>\begin{enumerate}&nbsp;<div><br /></div>\item feature $x$&nbsp;<div><br /></div>\item state of nature or class $C_j$&nbsp;<div><br /></div>\item action $\alpha_i$&nbsp;<div><br /></div>\item loss $L(\alpha_i \mid C_j)$ (cost for performing action $\alpha_i$ in&nbsp;<div><br /></div>state of nature $C_j$&nbsp;<div><br /></div>\item conditional risk $R(\alpha_i \mid x) = \sum \limits_{j=1}^{c} L(\alpha_i&nbsp;<div><br /></div>\mid C_j) p(C_j | x)$ (expected loss)&nbsp;<div><br /></div>\item decision rule $\alpha(x)$ (function that returns action $\alpha_i$ to&nbsp;<div><br /></div>take for an observation $x$&nbsp;<div><br /></div>\item risk $R=\int R(\alpha(x) \mid x) p(x) dx$ (expected loss associated with&nbsp;<div><br /></div>decision rule)&nbsp;<div><br /></div>\end{enumerate}&nbsp;<div><br /></div>[/latex] &nbsp;<div><br /></div>
Decision Theory: Goal -- Probability &nbsp;<div><br /></div>&nbsp;<div><br /></div> &nbsp;<div><br /></div>	 &nbsp;<div><br /></div>[latex]&nbsp;<div><br /></div>\begin{itemize}&nbsp;<div><br /></div>\item Goal: find decision rule that minimizes risk&nbsp;<div><br /></div>\item pick $\alpha(x)$ st. $R(\alpha(x))$ is minimal for any $x$&nbsp;<div><br /></div>\end{itemize}&nbsp;<div><br /></div>use Bayes decision rule:&nbsp;<div><br /></div>\begin{itemize}&nbsp;<div><br /></div>\item for all $i$ compute conditional risk:&nbsp;<div><br /></div>\begin{equation*}&nbsp;<div><br /></div>R(\alpha_i \mid x) = \sum \limits_{j=1}^{c} L(\alpha_i \mid C_j) p(C_j \mid x)&nbsp;<div><br /></div>\end{equation*}&nbsp;<div><br /></div>\item select $\alpha_i$ for which $R(\alpha_i \mid x)$ is minimum&nbsp;<div><br /></div>\end{itemize}&nbsp;<div><br /></div>[/latex] &nbsp;<div><br /></div>
Minimum Error rate classification: Setup -- Probability &nbsp;<div><br /></div> &nbsp;<div><br /></div>	 &nbsp;<div><br /></div>[latex]&nbsp;<div><br /></div>\begin{enumerate}&nbsp;<div><br /></div>\item classification problem $=$ c classes $C_j$&nbsp;<div><br /></div>\item action $\alpha_i$ is to decide that state of nature is $C_j$&nbsp;<div><br /></div>\item typical loss function: zero-one loss:&nbsp;<div><br /></div>\begin{equation*}&nbsp;<div><br /></div>L(\alpha_i \mid C_j) = 0 \text{ if } i = j \text{ else } 1&nbsp;<div><br /></div>\end{equation*}&nbsp;<div><br /></div>\item in that case: risk equal to probability of error, since:&nbsp;<div><br /></div>\begin{align*}&nbsp;<div><br /></div>R(\alpha_i \mid x) &= \sum \limits_{j=1}^{c} L(\alpha_i \mid C_j) p(C_j \mid&nbsp;<div><br /></div>x)\\&nbsp;<div><br /></div>&= \sum \limits_{i \neq j} p(C_j \mid x)\\&nbsp;<div><br /></div>&= 1 - p(C_i \mid x)&nbsp;<div><br /></div>\end{align*}&nbsp;<div><br /></div>&nbsp;<div><br /></div>\end{enumerate}&nbsp;<div><br /></div>[/latex] &nbsp;<div><br /></div>
Minimum Error rate classification: Summary of idea -- Probability &nbsp;<div><br /></div>&nbsp;<div><br /></div> &nbsp;<div><br /></div>	 &nbsp;<div><br /></div>[latex]&nbsp;<div><br /></div>\begin{itemize}&nbsp;<div><br /></div>\item to minimize risk $\rightarrow$ maximize conditional risk&nbsp;<div><br /></div>\item to minimize conditional risk $\rightarrow$ minimize average probability&nbsp;<div><br /></div>of error&nbsp;<div><br /></div>\item to minimize average probability of error $\rightarrow$ maximize posterior&nbsp;<div><br /></div>$p(C_i \mid x)$&nbsp;<div><br /></div>\item Note: Bayes theorem can be used to express posterior as $p(x \mid C_i)&nbsp;<div><br /></div>p(C_i)$&nbsp;<div><br /></div>\end{itemize}&nbsp;<div><br /></div>&nbsp;<div><br /></div>[/latex] &nbsp;<div><br /></div>
